{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.misc import imresize\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driving_log = pd.read_csv('data/data/driving_log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "center_images, right_images, left_images = driving_log['center'], driving_log['right'], driving_log['left']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_images = (pd.concat([right_images, center_images]))\n",
    "data_images = np.array(pd.concat([data_images, left_images]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24108"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_the_image(img, steer):\n",
    "    seed = np.random.randint(2)\n",
    "    if seed == 1:\n",
    "        img = np.fliplr(img)\n",
    "        steer = -steer\n",
    "    return img, steer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorspace(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2HSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "row, col = 16, 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img_resize(img):\n",
    "    w, h = img.size\n",
    "    img = img.crop((0, h*0.3, w, h-22))\n",
    "    image_resize = imresize(img, (row, col))\n",
    "    image = np.asarray(image_resize)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brightness(img):\n",
    "    seed = np.random.randint(2)\n",
    "    if seed == 1:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        random_bright = np.random.uniform(0.5,0.9)\n",
    "        img[:,:,2] = img[:,:,2] * random_bright\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_HSV2RGB)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "steering_center, steering_right, steering_left = driving_log['steering'],  (driving_log['steering'] - 0.15), (driving_log['steering'] + 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "steering_angles = (pd.concat([steering_right, steering_center]))\n",
    "steering_angles = np.array(pd.concat([steering_angles, steering_left]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24108"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(steering_angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsampling(steer, down_threshold):\n",
    "    \n",
    "#down_threshold = 0.8\n",
    "    sample = []\n",
    "    for i in range(len(steer)):\n",
    "        if abs(steer[i]) < 0.1:\n",
    "        #print (1)\n",
    "            if np.random.uniform(0,1) < down_threshold:\n",
    "                sample.append(i)\n",
    "        \n",
    "        else:\n",
    "            sample.append(i)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24108"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(steering_angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21987"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(downsampling(steering_angles, 0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = shuffle(data_images, steering_angles)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=0, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(batch_size, data, labels):\n",
    "    batch_images = np.zeros(shape=(batch_size,row,col,3), dtype=np.float32)\n",
    "    batch_labels = np.zeros(shape=(batch_size), dtype=np.float32)\n",
    "    #batch_size = 100\n",
    "    while True:\n",
    "        down_sample = downsampling(labels, 0.75)\n",
    "        steer_downsampled = labels[down_sample]\n",
    "        data_downsampled = data[down_sample]\n",
    "        shuffle = np.random.randint(len(down_sample), size= len(down_sample))\n",
    "        image_files = data_downsampled[shuffle]\n",
    "        steering = steer_downsampled[shuffle] \n",
    "        #np.random.shuffle(image_files)\n",
    "        for i in range(batch_size):\n",
    "            img_path =  os.path.join('data/data/{}'.format(image_files[i]))#.format(i)\n",
    "            img_path = ''.join(img_path.split())\n",
    "            image = Image.open(img_path)\n",
    "            steer = steering[i]\n",
    "            # some pre-processing with the image\n",
    "            image = img_resize(image)\n",
    "            image, steer = flip_the_image(image, steer)\n",
    "            image = brightness(image)\n",
    "            batch_labels[i] = steer\n",
    "            #batch_images.append(image)\n",
    "            batch_images[i] = image\n",
    "        #batch_images = np.array(batch_images)\n",
    "        yield batch_images, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gen = (generator(128, X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_gen = (generator(128, X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Activation\n",
    "from keras.layers import Conv2D, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2, activity_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.core import Lambda\n",
    "from keras.layers.pooling import MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 16, 32, 3)     0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 14, 30, 8)     224         lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 4, 10, 8)      0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 4, 10, 8)      0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 320)           0           dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1)             321         flatten_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 545\n",
      "Trainable params: 545\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x / 255 - 0.5, input_shape=(row, col, 3)))\n",
    "\n",
    "model.add(Conv2D(8, 3, 3, border_mode='valid', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1)) # there should be no activation function\n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.001)\n",
    "model.compile(loss='mse',\n",
    "              optimizer= adam,\n",
    "              metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "19968/20000 [============================>.] - ETA: 0s - loss: 0.0149 - mean_absolute_error: 0.0915"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rahul/anaconda3/lib/python3.5/site-packages/keras/engine/training.py:1527: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20096/20000 [==============================] - 47s - loss: 0.0149 - mean_absolute_error: 0.0914 - val_loss: 0.0142 - val_mean_absolute_error: 0.0860\n",
      "Epoch 2/35\n",
      "20096/20000 [==============================] - 45s - loss: 0.0149 - mean_absolute_error: 0.0912 - val_loss: 0.0142 - val_mean_absolute_error: 0.0860\n",
      "Epoch 3/35\n",
      "20096/20000 [==============================] - 45s - loss: 0.0151 - mean_absolute_error: 0.0915 - val_loss: 0.0142 - val_mean_absolute_error: 0.0879\n",
      "Epoch 4/35\n",
      "20096/20000 [==============================] - 44s - loss: 0.0151 - mean_absolute_error: 0.0911 - val_loss: 0.0137 - val_mean_absolute_error: 0.0862\n",
      "Epoch 5/35\n",
      "20096/20000 [==============================] - 44s - loss: 0.0151 - mean_absolute_error: 0.0918 - val_loss: 0.0154 - val_mean_absolute_error: 0.0884\n",
      "Epoch 6/35\n",
      "20096/20000 [==============================] - 44s - loss: 0.0149 - mean_absolute_error: 0.0912 - val_loss: 0.0144 - val_mean_absolute_error: 0.0877\n",
      "Epoch 7/35\n",
      "20096/20000 [==============================] - 47s - loss: 0.0147 - mean_absolute_error: 0.0908 - val_loss: 0.0139 - val_mean_absolute_error: 0.0864\n",
      "Epoch 8/35\n",
      "20096/20000 [==============================] - 46s - loss: 0.0152 - mean_absolute_error: 0.0920 - val_loss: 0.0138 - val_mean_absolute_error: 0.0861\n",
      "Epoch 9/35\n",
      "20096/20000 [==============================] - 45s - loss: 0.0155 - mean_absolute_error: 0.0923 - val_loss: 0.0134 - val_mean_absolute_error: 0.0853\n",
      "Epoch 10/35\n",
      "20096/20000 [==============================] - 45s - loss: 0.0152 - mean_absolute_error: 0.0914 - val_loss: 0.0146 - val_mean_absolute_error: 0.0889\n",
      "Epoch 11/35\n",
      "20096/20000 [==============================] - 45s - loss: 0.0147 - mean_absolute_error: 0.0907 - val_loss: 0.0145 - val_mean_absolute_error: 0.0875\n",
      "Epoch 12/35\n",
      "20096/20000 [==============================] - 45s - loss: 0.0143 - mean_absolute_error: 0.0900 - val_loss: 0.0142 - val_mean_absolute_error: 0.0870\n",
      "Epoch 13/35\n",
      "20096/20000 [==============================] - 45s - loss: 0.0151 - mean_absolute_error: 0.0923 - val_loss: 0.0152 - val_mean_absolute_error: 0.0895\n",
      "Epoch 14/35\n",
      "20096/20000 [==============================] - 45s - loss: 0.0146 - mean_absolute_error: 0.0910 - val_loss: 0.0138 - val_mean_absolute_error: 0.0857\n",
      "Epoch 15/35\n",
      "20096/20000 [==============================] - 45s - loss: 0.0151 - mean_absolute_error: 0.0914 - val_loss: 0.0144 - val_mean_absolute_error: 0.0870\n",
      "Epoch 16/35\n",
      "20096/20000 [==============================] - 45s - loss: 0.0148 - mean_absolute_error: 0.0911 - val_loss: 0.0146 - val_mean_absolute_error: 0.0896\n",
      "Epoch 17/35\n",
      "20096/20000 [==============================] - 46s - loss: 0.0147 - mean_absolute_error: 0.0912 - val_loss: 0.0143 - val_mean_absolute_error: 0.0859\n",
      "Epoch 18/35\n",
      "20096/20000 [==============================] - 45s - loss: 0.0151 - mean_absolute_error: 0.0915 - val_loss: 0.0139 - val_mean_absolute_error: 0.0863\n",
      "Epoch 19/35\n",
      "20096/20000 [==============================] - 45s - loss: 0.0145 - mean_absolute_error: 0.0907 - val_loss: 0.0142 - val_mean_absolute_error: 0.0868\n",
      "Epoch 20/35\n",
      "20096/20000 [==============================] - 45s - loss: 0.0148 - mean_absolute_error: 0.0908 - val_loss: 0.0143 - val_mean_absolute_error: 0.0872\n",
      "Epoch 21/35\n",
      "20096/20000 [==============================] - 45s - loss: 0.0146 - mean_absolute_error: 0.0901 - val_loss: 0.0149 - val_mean_absolute_error: 0.0886\n",
      "Epoch 22/35\n",
      "20096/20000 [==============================] - 45s - loss: 0.0146 - mean_absolute_error: 0.0908 - val_loss: 0.0142 - val_mean_absolute_error: 0.0859\n",
      "Epoch 23/35\n",
      "20096/20000 [==============================] - 45s - loss: 0.0144 - mean_absolute_error: 0.0904 - val_loss: 0.0140 - val_mean_absolute_error: 0.0863\n",
      "Epoch 24/35\n",
      "20096/20000 [==============================] - 46s - loss: 0.0150 - mean_absolute_error: 0.0910 - val_loss: 0.0141 - val_mean_absolute_error: 0.0859\n",
      "Epoch 25/35\n",
      "20096/20000 [==============================] - 45s - loss: 0.0149 - mean_absolute_error: 0.0908 - val_loss: 0.0144 - val_mean_absolute_error: 0.0874\n",
      "Epoch 26/35\n",
      "20096/20000 [==============================] - 45s - loss: 0.0148 - mean_absolute_error: 0.0899 - val_loss: 0.0153 - val_mean_absolute_error: 0.0878\n",
      "Epoch 27/35\n",
      "20096/20000 [==============================] - 45s - loss: 0.0148 - mean_absolute_error: 0.0907 - val_loss: 0.0134 - val_mean_absolute_error: 0.0841\n",
      "Epoch 28/35\n",
      "20096/20000 [==============================] - 45s - loss: 0.0157 - mean_absolute_error: 0.0928 - val_loss: 0.0140 - val_mean_absolute_error: 0.0861\n",
      "Epoch 29/35\n",
      "20096/20000 [==============================] - 46s - loss: 0.0152 - mean_absolute_error: 0.0921 - val_loss: 0.0140 - val_mean_absolute_error: 0.0863\n",
      "Epoch 30/35\n",
      "20096/20000 [==============================] - 45s - loss: 0.0146 - mean_absolute_error: 0.0903 - val_loss: 0.0146 - val_mean_absolute_error: 0.0865\n",
      "Epoch 31/35\n",
      "20096/20000 [==============================] - 45s - loss: 0.0152 - mean_absolute_error: 0.0920 - val_loss: 0.0146 - val_mean_absolute_error: 0.0883\n",
      "Epoch 32/35\n",
      "20096/20000 [==============================] - 45s - loss: 0.0149 - mean_absolute_error: 0.0913 - val_loss: 0.0146 - val_mean_absolute_error: 0.0865\n",
      "Epoch 33/35\n",
      "20096/20000 [==============================] - 46s - loss: 0.0150 - mean_absolute_error: 0.0916 - val_loss: 0.0142 - val_mean_absolute_error: 0.0868\n",
      "Epoch 34/35\n",
      "20096/20000 [==============================] - 45s - loss: 0.0150 - mean_absolute_error: 0.0914 - val_loss: 0.0141 - val_mean_absolute_error: 0.0855\n",
      "Epoch 35/35\n",
      "20096/20000 [==============================] - 45s - loss: 0.0148 - mean_absolute_error: 0.0911 - val_loss: 0.0143 - val_mean_absolute_error: 0.0866\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_gen, nb_epoch =35,\n",
    "                             samples_per_epoch=20000,verbose=1,\n",
    "                              validation_data=valid_gen,nb_val_samples=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
